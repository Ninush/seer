return(training_set)
#' preparation of training set
#'
#' Preparation of a training set for random forest training
#' @param accuracy_set output from the fcast_accuracy
#' @param feature_set output from the cal_features
#' @return dataframe consisting features and classlabels
#' @export
prepare_trainingset <- function(accuracy_set, feature_set){
accuracy_measures <- as.data.frame(accuracy_set$accuracy)
minimum_accuracy <- apply(accuracy_measures,1,min)
inf_indices <- which(minimum_accuracy==Inf)
na_indices <- which(is.na(minimum_accuracy)==TRUE)
rmv_indices <- c(inf_indices, na_indices)
accuracy_measures$ARIMA_name <- as.character(accuracy_set$ARIMA)
accuracy_measures$ETS_name <- as.character(accuracy_set$ETS)
training_set <- dplyr::bind_cols(feature_set, accuracy_measures)
if(length(rmv_indices)!=0) {training_set <- training_set[-rmv_indices, ]}
# find the classlabel corresponds to minimum
colnames_accuracyMatrix <- colnames(accuracy_set$accuracy)
df_accuracy <- dplyr::select(training_set, colnames_accuracyMatrix)
training_set$min_label <- as.character(seer::classlabel(df_accuracy))
training_set$model_names <- ifelse(training_set$min_label == "arima", training_set$ARIMA_name, training_set$min_label)
training_set$model_names <- ifelse(training_set$min_label == "ets", training_set$ETS_name, training_set$min_label)
training_set$model_names <- as.character(training_set$model_names)
# classify labe names
df_modnames <- split_names(training_set$model_names)
classlabel <- classify_labels(df_modnames)
training_set$classlabels <- classlabel
# extract complete cases only
training_set <- training_set[complete.cases(training_set),]
training_set <- dplyr::select(training_set, c(colnames(feature_set), "classlabels"))
return(training_set)
}
#'@example
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
prepare_trainingset(acc_set, fea_set)
a <- prepare_trainingset(acc_set, fea_set)
dim(a)
#' preparation of training set
#'
#' Preparation of a training set for random forest training
#' @param accuracy_set output from the fcast_accuracy
#' @param feature_set output from the cal_features
#' @return dataframe consisting features and classlabels
#' @export
prepare_trainingset <- function(accuracy_set, feature_set){
accuracy_measures <- as.data.frame(accuracy_set$accuracy)
minimum_accuracy <- apply(accuracy_measures,1,min)
inf_indices <- which(minimum_accuracy==Inf)
na_indices <- which(is.na(minimum_accuracy)==TRUE)
rmv_indices <- c(inf_indices, na_indices)
accuracy_measures$ARIMA_name <- as.character(accuracy_set$ARIMA)
accuracy_measures$ETS_name <- as.character(accuracy_set$ETS)
training_set <- dplyr::bind_cols(feature_set, accuracy_measures)
if(length(rmv_indices)!=0) {training_set <- training_set[-rmv_indices, ]}
# find the classlabel corresponds to minimum
colnames_accuracyMatrix <- colnames(accuracy_set$accuracy)
df_accuracy <- dplyr::select(training_set, colnames_accuracyMatrix)
training_set$min_label <- as.character(seer::classlabel(df_accuracy))
training_set$model_names <- ifelse(training_set$min_label == "arima", training_set$ARIMA_name, training_set$min_label)
training_set$model_names <- ifelse(training_set$min_label == "ets", training_set$ETS_name, training_set$min_label)
training_set$model_names <- as.character(training_set$model_names)
# classify labe names
df_modnames <- split_names(training_set$model_names)
classlabel <- classify_labels(df_modnames)
training_set$classlabels <- classlabel
# extract complete cases only
training_set <- training_set[complete.cases(training_set),]
models <- data.frame(training_set$ARIMA_names, training_set$ETS_names, training_set$min_label, training_set$model_label)
training_set <- dplyr::select(training_set, c(colnames(feature_set), "classlabels"))
train <- list(models, training_set)
return(train)
}
#'@example
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
prepare_trainingset(acc_set, fea_set)
accuracy_measures <- as.data.frame(accuracy_set$accuracy)
minimum_accuracy <- apply(accuracy_measures,1,min)
inf_indices <- which(minimum_accuracy==Inf)
na_indices <- which(is.na(minimum_accuracy)==TRUE)
rmv_indices <- c(inf_indices, na_indices)
accuracy_measures$ARIMA_name <- as.character(accuracy_set$ARIMA)
accuracy_measures$ETS_name <- as.character(accuracy_set$ETS)
training_set <- dplyr::bind_cols(feature_set, accuracy_measures)
if(length(rmv_indices)!=0) {training_set <- training_set[-rmv_indices, ]}
# find the classlabel corresponds to minimum
colnames_accuracyMatrix <- colnames(accuracy_set$accuracy)
df_accuracy <- dplyr::select(training_set, colnames_accuracyMatrix)
training_set$min_label <- as.character(seer::classlabel(df_accuracy))
training_set$model_names <- ifelse(training_set$min_label == "arima", training_set$ARIMA_name, training_set$min_label)
training_set$model_names <- ifelse(training_set$min_label == "ets", training_set$ETS_name, training_set$min_label)
training_set$model_names <- as.character(training_set$model_names)
# classify labe names
df_modnames <- split_names(training_set$model_names)
classlabel <- classify_labels(df_modnames)
training_set$classlabels <- classlabel
# extract complete cases only
training_set <- training_set[complete.cases(training_set),]
training_set$ARIMA_names
training_set
#' preparation of training set
#'
#' Preparation of a training set for random forest training
#' @param accuracy_set output from the fcast_accuracy
#' @param feature_set output from the cal_features
#' @return dataframe consisting features and classlabels
#' @export
prepare_trainingset <- function(accuracy_set, feature_set){
accuracy_measures <- as.data.frame(accuracy_set$accuracy)
minimum_accuracy <- apply(accuracy_measures,1,min)
inf_indices <- which(minimum_accuracy==Inf)
na_indices <- which(is.na(minimum_accuracy)==TRUE)
rmv_indices <- c(inf_indices, na_indices)
accuracy_measures$ARIMA_name <- as.character(accuracy_set$ARIMA)
accuracy_measures$ETS_name <- as.character(accuracy_set$ETS)
training_set <- dplyr::bind_cols(feature_set, accuracy_measures)
if(length(rmv_indices)!=0) {training_set <- training_set[-rmv_indices, ]}
# find the classlabel corresponds to minimum
colnames_accuracyMatrix <- colnames(accuracy_set$accuracy)
df_accuracy <- dplyr::select(training_set, colnames_accuracyMatrix)
training_set$min_label <- as.character(seer::classlabel(df_accuracy))
training_set$model_names <- ifelse(training_set$min_label == "arima", training_set$ARIMA_name, training_set$min_label)
training_set$model_names <- ifelse(training_set$min_label == "ets", training_set$ETS_name, training_set$min_label)
training_set$model_names <- as.character(training_set$model_names)
# classify labe names
df_modnames <- split_names(training_set$model_names)
classlabel <- classify_labels(df_modnames)
training_set$classlabels <- classlabel
# extract complete cases only
training_set <- training_set[complete.cases(training_set),]
models <- data.frame(training_set$ARIMA_name, training_set$ETS_name, training_set$min_label, training_set$model_names)
training_set <- dplyr::select(training_set, c(colnames(feature_set), "classlabels"))
train <- list(models, training_set)
return(train)
}
#'@example
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
prepare_trainingset(acc_set, fea_set)
#' preparation of training set
#'
#' Preparation of a training set for random forest training
#' @param accuracy_set output from the fcast_accuracy
#' @param feature_set output from the cal_features
#' @return dataframe consisting features and classlabels
#' @export
prepare_trainingset <- function(accuracy_set, feature_set){
accuracy_measures <- as.data.frame(accuracy_set$accuracy)
minimum_accuracy <- apply(accuracy_measures,1,min)
inf_indices <- which(minimum_accuracy==Inf)
na_indices <- which(is.na(minimum_accuracy)==TRUE)
rmv_indices <- c(inf_indices, na_indices)
accuracy_measures$ARIMA_name <- as.character(accuracy_set$ARIMA)
accuracy_measures$ETS_name <- as.character(accuracy_set$ETS)
training_set <- dplyr::bind_cols(feature_set, accuracy_measures)
if(length(rmv_indices)!=0) {training_set <- training_set[-rmv_indices, ]}
# find the classlabel corresponds to minimum
colnames_accuracyMatrix <- colnames(accuracy_set$accuracy)
df_accuracy <- dplyr::select(training_set, colnames_accuracyMatrix)
training_set$min_label <- as.character(seer::classlabel(df_accuracy))
training_set$model_names <- ifelse(training_set$min_label == "arima", training_set$ARIMA_name, training_set$min_label)
training_set$model_names <- ifelse(training_set$min_label == "ets", training_set$ETS_name, training_set$min_label)
training_set$model_names <- as.character(training_set$model_names)
# classify labe names
df_modnames <- split_names(training_set$model_names)
classlabel <- classify_labels(df_modnames)
training_set$classlabels <- classlabel
# extract complete cases only
training_set <- training_set[complete.cases(training_set),]
models <- data.frame(training_set$ARIMA_name, training_set$ETS_name, training_set$min_label, training_set$model_names)
training_set <- dplyr::select(training_set, c(colnames(feature_set), "classlabels"))
train <- list(modelinfo=models, trainingset=training_set)
return(train)
}
#'@example
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
outcome <- prepare_trainingset(acc_set, fea_set)
outcome$training_set
outcome$trainingset
outcome$modelinfo
#' preparation of training set
#'
#' Preparation of a training set for random forest training
#' @param accuracy_set output from the fcast_accuracy
#' @param feature_set output from the cal_features
#' @return dataframe consisting features and classlabels
#' @export
prepare_trainingset <- function(accuracy_set, feature_set){
accuracy_measures <- as.data.frame(accuracy_set$accuracy)
minimum_accuracy <- apply(accuracy_measures,1,min)
inf_indices <- which(minimum_accuracy==Inf)
na_indices <- which(is.na(minimum_accuracy)==TRUE)
rmv_indices <- c(inf_indices, na_indices)
accuracy_measures$ARIMA_name <- as.character(accuracy_set$ARIMA)
accuracy_measures$ETS_name <- as.character(accuracy_set$ETS)
training_set <- dplyr::bind_cols(feature_set, accuracy_measures)
if(length(rmv_indices)!=0) {training_set <- training_set[-rmv_indices, ]}
# find the classlabel corresponds to minimum
colnames_accuracyMatrix <- colnames(accuracy_set$accuracy)
df_accuracy <- dplyr::select(training_set, colnames_accuracyMatrix)
training_set$min_label <- as.character(seer::classlabel(df_accuracy))
training_set$model_names <- ifelse(training_set$min_label == "arima", training_set$ARIMA_name, training_set$min_label)
training_set$model_names <- ifelse(training_set$min_label == "ets", training_set$ETS_name, training_set$min_label)
training_set$model_names <- as.character(training_set$model_names)
# classify labe names
df_modnames <- split_names(training_set$model_names)
classlabel <- classify_labels(df_modnames)
training_set$classlabels <- classlabel
# extract complete cases only
training_set <- training_set[complete.cases(training_set),]
models <- data.frame(ARIMA_name=training_set$ARIMA_name, ETS_name=training_set$ETS_name,
min_label=training_set$min_label, model_names=training_set$model_names)
training_set <- dplyr::select(training_set, c(colnames(feature_set), "classlabels"))
train <- list(modelinfo=models, trainingset=training_set)
return(train)
}
#'@example
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
outcome <- prepare_trainingset(acc_set, fea_set)
outcome$trainingset
outcome$modelinfo
library(seer)
library(seer)
library(seer)
library(seer)
library(seer)
library(seer)
library(seer)
library(seer)
library(seer)
#' preparation of training set
#'
#' Preparation of a training set for random forest training
#' @param accuracy_set output from the fcast_accuracy
#' @param feature_set output from the cal_features
#' @return dataframe consisting features and classlabels
#' @export
prepare_trainingset <- function(accuracy_set, feature_set){
accuracy_measures <- as.data.frame(accuracy_set$accuracy)
minimum_accuracy <- apply(accuracy_measures,1,min)
inf_indices <- which(minimum_accuracy==Inf)
na_indices <- which(is.na(minimum_accuracy)==TRUE)
rmv_indices <- c(inf_indices, na_indices)
accuracy_measures$ARIMA_name <- as.character(accuracy_set$ARIMA)
accuracy_measures$ETS_name <- as.character(accuracy_set$ETS)
training_set <- dplyr::bind_cols(feature_set, accuracy_measures)
if(length(rmv_indices)!=0) {training_set <- training_set[-rmv_indices, ]}
# find the classlabel corresponds to minimum
colnames_accuracyMatrix <- colnames(accuracy_set$accuracy)
df_accuracy <- dplyr::select(training_set, colnames_accuracyMatrix)
training_set$min_label <- as.character(seer::classlabel(df_accuracy))
training_set$model_names <- ifelse(training_set$min_label == "arima", training_set$ARIMA_name, training_set$min_label)
training_set$model_names <- ifelse(training_set$min_label == "ets", training_set$ETS_name, training_set$model_names)
training_set$model_names <- as.character(training_set$model_names)
# classify labe names
df_modnames <- split_names(training_set$model_names)
classlabel <- classify_labels(df_modnames)
training_set$classlabels <- classlabel
# extract complete cases only
training_set <- training_set[complete.cases(training_set),]
models <- data.frame(ARIMA_name=training_set$ARIMA_name, ETS_name=training_set$ETS_name,
min_label=training_set$min_label, model_names=training_set$model_names)
training_set <- dplyr::select(training_set, c(colnames(feature_set), "classlabels"))
train <- list(modelinfo=models, trainingset=training_set)
return(train)
}
#'@example
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
library(seer)
library(tsfeatures)
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
outcome <- prepare_trainingset(acc_set, fea_set)
rm(list=ls())
#' preparation of training set
#'
#' Preparation of a training set for random forest training
#' @param accuracy_set output from the fcast_accuracy
#' @param feature_set output from the cal_features
#' @return dataframe consisting features and classlabels
#' @export
prepare_trainingset <- function(accuracy_set, feature_set){
accuracy_measures <- as.data.frame(accuracy_set$accuracy)
minimum_accuracy <- apply(accuracy_measures,1,min)
inf_indices <- which(minimum_accuracy==Inf)
na_indices <- which(is.na(minimum_accuracy)==TRUE)
rmv_indices <- c(inf_indices, na_indices)
accuracy_measures$ARIMA_name <- as.character(accuracy_set$ARIMA)
accuracy_measures$ETS_name <- as.character(accuracy_set$ETS)
training_set <- dplyr::bind_cols(feature_set, accuracy_measures)
if(length(rmv_indices)!=0) {training_set <- training_set[-rmv_indices, ]}
# find the classlabel corresponds to minimum
colnames_accuracyMatrix <- colnames(accuracy_set$accuracy)
df_accuracy <- dplyr::select(training_set, colnames_accuracyMatrix)
training_set$min_label <- as.character(seer::classlabel(df_accuracy))
training_set$model_names <- ifelse(training_set$min_label == "arima", training_set$ARIMA_name, training_set$min_label)
training_set$model_names <- ifelse(training_set$min_label == "ets", training_set$ETS_name, training_set$model_names)
training_set$model_names <- as.character(training_set$model_names)
# classify labe names
df_modnames <- split_names(training_set$model_names)
classlabel <- classify_labels(df_modnames)
training_set$classlabels <- classlabel
# extract complete cases only
training_set <- training_set[complete.cases(training_set),]
models <- data.frame(ARIMA_name=training_set$ARIMA_name, ETS_name=training_set$ETS_name,
min_label=training_set$min_label, model_names=training_set$model_names)
training_set <- dplyr::select(training_set, c(colnames(feature_set), "classlabels"))
train <- list(modelinfo=models, trainingset=training_set)
return(train)
}
library(seer)
library(tsfeatures)
libary(forecast)
library(forecast)
#'@example
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
outcome <- prepare_trainingset(acc_set, fea_set)
outcome$trainingset
outcome$modelinfo
library(seer)
library(forecast)
library(seer)
library(seer)
library(randomForest)
?randomForest
library(seer)
library(seer)
library(seer)
library(seer)
#' @param M if TRUE, y is considered to be a Mcomp data object
#' @param Future  if future=TRUE, the simulated observations are conditional on the historical observations.
#' In other words, they are possible future sample paths of the time series. But if future=FALSE, the historical
#' data are ignored, and the simulations are possible realizations of the time series model that
#' are not connected to the original data.
#' @param Length length of the simulated time series. If future = FALSE, the Length agument should be NA.
#' @param extralength extra length need to be added for simulated time series
#' @return A list of time series.
#' @author Thiyanga Talagala
#' @export
sim_etsbased <- function(y, Nsim, Combine=TRUE, M=TRUE, Future=FALSE, Length=NA, extralength=NA){
if (M ==TRUE){
if ("Combine"==TRUE){
train <- y$x
test <-  y$xx
combined <- ts.union(train, test)
combined <- pmin(combined[,1], combined[,2], na.rm = TRUE)
}else{
combined <- y$x}
}else{
combined <- y
}
fit <- forecast::ets(combined)
if (!is.na(Length)){length_series <- Length
} else if (!is.na(extralength)) {
length_series <- length(combined)+extralength
} else {
length_series <- length(combined)
}
mat <- list()
for(i in 1:Nsim){
mat[[i]] <- simulate(fit, nsim=length_series, future=FALSE)}
return (mat)
}
y <- rnorm(100)
sim_etsbased(y, 2, Combine=FALSE, M=FALSE, Future=TRUE)
y <- norm(5)
y <- rnorm(5)
y
sim_etsbased(y, 2, Combine=FALSE, M=FALSE, Future=TRUE)
set.seed(8)
sim_etsbased(y, 2, Combine=FALSE, M=FALSE, Future=TRUE)
sim_etsbased(y, 2, Combine=FALSE, M=FALSE, Future=TRUE)
set.seed(8)
sim_etsbased(y, 2, Combine=FALSE, M=FALSE, Future=TRUE)
library(seer)
m1 <- sumbset(M1, "mpnthly")
m1 <- sumbset(M1, "monthly")
library(Mcomp)
m1 <- sumbset(M1, "monthly")
m1 <- subset(M1, "monthly")
y <- m1[[1]]$x
y
sdiff <- diff(y, lag=m, differences=1)
sdiff <- diff(y, lag=12, differences=1)
lagmax=13L
sdiff <- diff(y, lag=m, differences=1)
m=12
sdiff <- diff(y, lag=m, differences=1)
sdiff
1187650-937352
SEacf_1 <- sEacfy$acf[2L]
sdiff <- diff(y, lag=m, differences=1)
sEacfy <- stats::acf(sdiff, lag.max = lagmax, plot = FALSE)
SEacf_1 <- sEacfy$acf[2L]
SEseas_acf1 <- sEacfy$acf[m+1L]
sEacfy$acf
sEacfy$acf[-1L]
sEacfy$acf[-2L:6L]
sEacfy$acf[2L:6L]
SEseas_acf1
y <- rnorm(10)
acfy <- stats::acf(y, lag.max = 5L, plot = FALSE)
acfdiff1y <- stats::acf(diff(y, 1), lag.max = 5L, plot = FALSE)
acfdiff2y <- stats::acf(diff(y, 2), lag.max = 5L, plot = FALSE)
sum_of_sq_acf5 <- sum((acfy$acf[-1L])^2)
sum_of_sq_acf5
sum_of_sq_acf5 <- sum((acfy$acf[2L:6L])^2)
sum_of_sq_acf5
library(seer)
library(seer)
vect_mod1 <- c("ARIMA(2,1,0)", "ARIMA(2,0,0)", "ARIMA(0,1,0)")
split_names(vect_mod1)
@example
vect_mod2 <- c("ARIMA(2,1,0) with drift", "ARIMA(2,0,0) with non-zero mean" ,"ARIMA(2,0,0) with non-zero mean" ,
"ARIMA(2,0,0) with non-zero mean" ,"ARIMA(0,0,1)", "ARIMA(2,0,0)(1,0,0)[12] with non-zero mean", "ARIMA(0,1,0)",
"ARIMA(0,1,0) with drift", "ARIMA(0,0,0)(0,1,0)[4]")
split_names(vect_mod2)
#' split the names of ARIMA and ETS models
#'
#' split the names of ARIMA, ETS models to model name, different number of parameters
#' in each case.
#'
#' @param models vector of model names
#' @return a dataframe where columns gives the description of model components
#' @export
split_names <- function(models){
# code random walk, random walk with drift, snaive and white noise
models <- dplyr::recode(models, "ARIMA(0,1,0)" = "rw")
models <- dplyr::recode(models, "ARIMA(0,1,0) with drift"="rwd")
models <- dplyr::recode(models, "ARIMA(0,0,0) with non-zero mean"="wn")
models <- dplyr::recode(models, "ARIMA(0,0,0) with zero mean"="wn")
models <- dplyr::recode(models, "ARIMA(0,0,0)(0,1,0)[4]"="snaive")
models <- dplyr::recode(models, "ARIMA(0,0,0)(0,1,0)[12]"="snaive")
# First identify the sarima models and rename them as "SARIMA"
toMatch_frequency <- c("[12]", "[4]")
index_sarima <- grepl(paste0(gsub("(\\[)","\\\\[", toMatch_frequency), collapse = "|"), models)
df1 <- data.frame(models=models, ind_sarima = index_sarima)
df1$models <- as.character(df1$models)
models <- ifelse(df1$ind_sarima == TRUE, "SARIMA", df1$models)
###Here we have choosen the separator as space(\\s), parenthesis ( \\( and \\) ) and commas (,)
df <- data.frame(stringr::str_split_fixed(models,"\\s|\\(|\\)|,",n=5))
#Rename basis the question, into follwing:
#p is the number of autoregressive terms(AR)
#d is the number of nonseasonal differences needed for stationarity(MA)
#q is the number of lagged forecast errors in the prediction equation(order of differencing)
names(df) <- c("Model","p","d","q","outcome")
# If the outcome column contains all "" stop the code from here
if(length(which(nchar(trimws(df$outcome))==0))==dim(df)[1]){
df <- dplyr::select(df, c("Model", "p", "d", "q"))
df$Model <- as.character(df$Model)
return(df)}
#cleaning the outcome column by replacing spaces and dashes with underscores
df$outcome_ <- gsub("\\s|-","_",trimws(df$outcome))
#using model.matrix to calculate the dummies for drift and non zero mean,
#for the value of 1 meaning True and 0 meaning False
dummy_mat <- data.frame(model.matrix(~outcome_-1,data=df))
df_final <- data.frame(df[,1:4],dummy_mat)
col_names_wanted <- c("Model", "p", "d", "q", "outcome_with_drift", "outcome_with_non_zero_mean")
col_names_available <- col_names_wanted[col_names_wanted %in% names(df_final)]
df_final <- df_final[,col_names_available]
df_final$Model <- as.character(df_final$Model)
return(df_final)
}
#' @example
library(seer)
vect_mod1 <- c("ARIMA(2,1,0)", "ARIMA(2,0,0)", "ARIMA(0,1,0)")
split_names(vect_mod1)
@example
vect_mod2 <- c("ARIMA(2,1,0) with drift", "ARIMA(2,0,0) with non-zero mean" ,"ARIMA(2,0,0) with non-zero mean" ,
"ARIMA(2,0,0) with non-zero mean" ,"ARIMA(0,0,1)", "ARIMA(2,0,0)(1,0,0)[12] with non-zero mean", "ARIMA(0,1,0)",
"ARIMA(0,1,0) with drift", "ARIMA(0,0,0)(0,1,0)[4]")
split_names(vect_mod2)
library(seer)
