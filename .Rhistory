# Seasonally adjusted data
sa <- seasadj(temp)
seascomp <- tail(temp$time.series,52)[,1]
temp
# STL decomposition
temp <- stl(ts_m4, s.window="periodic", robust=TRUE)
# STL decomposition
temp <- mstl(ts_m4)
head(temp)
temp$Seasonal52[52]
temp$Seasonal52
temp[52,]
temp[53,]
temp[2,]
temp[54,]
plot(temp)
?stlf
decomp <- stl(USAccDeaths,s.window="periodic")
decomp$time.series
decomp <- mstl(USAccDeaths)
decomp
# STL decomposition
temp <- stl(ts_m4, s.window="periodic", robust=TRUE)
temp
m4_weekly <- subset(M4, "daily")
ts_m4 <- m4_weekly[[1]]$x
plot(ts_m4)
# STL decomposition
temp <- stl(ts_m4, s.window="periodic", robust=TRUE)
temp
temp[100:673]
temp[100:673,]
# STL decomposition
temp <- stl(ts_m4, s.window="periodic", robust=TRUE)
temp[1,]
temp
temp$time.series
temp$time.series[365]
temp$time.series[366]
temp$time.series[300:366]
tail(temp$time.series)
tail(temp$time.series,50)
tail(temp$time.series,200)
tail(temp$time.series,300)
head(temp$time.series,367)
head(temp$time.series,300:367)
temp$time.series[300:367]
# STL decomposition
temp <- mstl(ts_m4, s.window="periodic", robust=TRUE)
temp
head(temp)
# STL decomposition
temp <- mstl(ts_m4, s.window="periodic", robust=TRUE)
head(temp)
tail(temp, 400)
head(temp, 370)
tail(temp, 400)
366*2
tail(temp, 732)
## fpp2
library(fpp2)
a <- mstl(calls)
head(a)
sa <- seasadj(a)
sa
head(a)
head(sa)
218.7847+10.1932177
218.7507+24.3451137
head(sa)
218.7447+10.1932177
218.7507+24.3451137
temp$seasonal
fit <- stlf(ts_m4)
simulate(fit, nsim=5, futute=TRUE)
fit
simulate(fit$model, nsim=5, futute=TRUE)
stlf
m4_weekly <- subset(M4, "daily")
ts_m4 <- m4_weekly[[3]]$x
plot(ts_m4)
mstl(ts_m4)
frequency(ts_m4)
stlf(ts_m4)
m4_weekly <- subset(M4, "weekly")
ts_m4 <- m4_weekly[[3]]$x
ts_m4
# mstl based simulations
fit <- stlf(ts_m4)
fit
simulate(fit, futute=FALSE, nsim=5)
simulate(fit$model, futute=FALSE, nsim=5)
simulate(fit$model, future=FALSE, nsim=5)
simulate(fit$model, future=TRUE, nsim=5)
simulate(fit$model, future=FALSE, nsim=5)
library(forecast)
length(USAccDeaths)
fit <- Arima(USAccDeaths)
s1 <- simulate(fit,future=FALSE)
s1
length(s1)
s2 <- simulate(fit, future=TRUE, nsim=20)
s2
length(s2)
simulate(fit, future=FALSE, nsim=5)
# mstl based simulations
fit_stlf <- stlf(ts_m4)
simulate(fit_stlf$model, future=TRUE, nsim=5)
simulate(fit_stlf$model, future=FALSE, nsim=5)
simulate(fit, future=FALSE, nsim=5)
simulate(fit, future=T, nsim=5)
m4_weekly <- subset(M4, "weekly")
ts_m4 <- m4_weekly[[3]]$x
plot(ts_m4)
frequency(ts_m4)
fit_tt <- stlf(ts_m4)
length(ts_m4)
2178+14
sim <- simulate(fit_tt$model, nsim=2192)
plot(sim)
frequency(sim)
52*2
#' @param M if TRUE, y is considered to be a Mcomp data object
#' @param Future if future=TRUE, the simulated observations are conditional on the historical observations.
#' In other words, they are possible future sample paths of the time series. But if future=FALSE, the historical
#' data are ignored, and the simulations are possible realizations of the time series model that
#' are not connected to the original data.
#' @param Length length of the simulated time series. If future = FALSE, the Length agument should be NA.
#' @param extralength extra length need to be added for simulated time series
#' @return A list of time series.
#' @author Thiyanga Talagala
#' @export
sim_mstlbased <- function(y, Nsim, Combine=TRUE, M=TRUE, Future=FALSE, Length=NA, extralength=NA){
if (M ==TRUE){
if ("Combine"==TRUE){
train <- y$x
test <-  y$xx
combined <- ts.union(train, test)
combined <- pmin(combined[,1], combined[,2], na.rm = TRUE)
}else{
combined <- y$x}
}else{
combined <- y
}
if(frequency(y)==1 | length(y) <= 2*frequency(y))
return(NA)
fit <- forecast::stlf(combined)
if (!is.na(Length)){length_series <- Length
} else if (!is.na(extralength)) {
length_series <- length(combined)+extralength
} else {
length_series <- length(combined)
}
mat <- list()
for(i in 1:Nsim){
mat[[i]] <- simulate(fit$model, nsim=length_series, future=Future)}
return (mat)
}
library(seer)
data(M4)
weekly_m4 <- subset(M3, "weekly")
weekly_m4 <- subset(M4, "weekly")
sim_mstlbased(weekly_m4[[1]], 2, Combine=FALSE, M=TRUE, Future=FALSE)
sim_mstlbased(weekly_m4[1], 2, Combine=FALSE, M=TRUE, Future=FALSE)
weekly_m4[1]
y <- weekly_m4[1]
combined <- y$x}
combined <- y$x
frequency(y)
frequency(weekly_m4[[1]]$x)
frequency(weekly_m4[1]$x)
sim_mstlbased(weekly_m4[[1]], 2, Combine=FALSE, M=TRUE, Future=FALSE)
y <- weekly_m4[[1]]
y
y <- weekly_m4[[1]]
combined <- y$x
#' @param M if TRUE, y is considered to be a Mcomp data object
#' @param Future if future=TRUE, the simulated observations are conditional on the historical observations.
#' In other words, they are possible future sample paths of the time series. But if future=FALSE, the historical
#' data are ignored, and the simulations are possible realizations of the time series model that
#' are not connected to the original data.
#' @param Length length of the simulated time series. If future = FALSE, the Length agument should be NA.
#' @param extralength extra length need to be added for simulated time series
#' @return A list of time series.
#' @author Thiyanga Talagala
#' @export
sim_mstlbased <- function(y, Nsim, Combine=TRUE, M=TRUE, Future=FALSE, Length=NA, extralength=NA){
if (M ==TRUE){
if ("Combine"==TRUE){
train <- y$x
test <-  y$xx
combined <- ts.union(train, test)
combined <- pmin(combined[,1], combined[,2], na.rm = TRUE)
}else{
combined <- y$x}
}else{
combined <- y
}
if(frequency(combined)==1 | length(combined) <= 2*frequency(combined))
return(NA)
fit <- forecast::stlf(combined)
if (!is.na(Length)){length_series <- Length
} else if (!is.na(extralength)) {
length_series <- length(combined)+extralength
} else {
length_series <- length(combined)
}
mat <- list()
for(i in 1:Nsim){
mat[[i]] <- simulate(fit$model, nsim=length_series, future=Future)}
return (mat)
}
#'@examples
library(seer)
data(M4)
weekly_m4 <- subset(M4, "weekly")
sim_mstlbased(weekly_m4[[1]], 2, Combine=FALSE, M=TRUE, Future=FALSE)
daily_m4 <- subset(M4, "daily")
sim_mstlbased(daily_m4[[3]], 2, Combine=FALSE, M=FALSE, Future=TRUE)
?one_of
??one_of
#' preparation of training set
#'
#' Preparation of a training set for random forest training
#' @param accuracy_set output from the fcast_accuracy
#' @param feature_set output from the cal_features
#' @return dataframe consisting features and classlabels
#' @export
prepare_trainingset <- function(accuracy_set, feature_set){
accuracy_measures <- as.data.frame(accuracy_set$accuracy)
minimum_accuracy <- apply(accuracy_measures,1,min, na.rm=TRUE)
inf_indices <- which(minimum_accuracy==Inf)
na_indices <- which(is.na(minimum_accuracy)==TRUE)
rmv_indices <- c(inf_indices, na_indices)
accuracy_measures$ARIMA_name <- as.character(accuracy_set$ARIMA)
accuracy_measures$ETS_name <- as.character(accuracy_set$ETS)
training_set <- dplyr::bind_cols(feature_set, accuracy_measures)
if(length(rmv_indices)!=0) {training_set <- training_set[-rmv_indices, ]}
# find the classlabel corresponds to minimum
colnames_accuracyMatrix <- colnames(accuracy_set$accuracy)
df_accuracy <- dplyr::select(training_set, colnames_accuracyMatrix)
training_set$min_label <- as.character(seer::classlabel(df_accuracy))
training_set$model_names <- ifelse(training_set$min_label == "arima", training_set$ARIMA_name, training_set$min_label)
training_set$model_names <- ifelse(training_set$min_label == "ets", training_set$ETS_name, training_set$model_names)
training_set$model_names <- as.character(training_set$model_names)
# classify labe names
df_modnames <- split_names(training_set$model_names)
classlabel <- classify_labels(df_modnames)
training_set$classlabels <- classlabel
# extract complete cases only
drop.cols <- colnames(accuracy_set$accuracy)
training_set <- training_set %>% select(-dplyr::one_of(drop.cols))
training_set <- training_set[complete.cases(training_set),]
models <- data.frame(ARIMA_name=training_set$ARIMA_name, ETS_name=training_set$ETS_name,
min_label=training_set$min_label, model_names=training_set$model_names)
training_set <- dplyr::select(training_set, c(colnames(feature_set), "classlabels"))
train <- list(modelinfo=models, trainingset=training_set)
return(train)
}
#'@example
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
library(seer)
library(Mcomp)
tslist <- list(M3[[1]], M3[[2]], M3[[3]], M3[[4]], M3[[5]])
acc_set <- fcast_accuracy(tslist=tslist,
models= c("arima","ets","rw","rwd", "theta", "nn", "snaive", "mstl"),
database ="M3", cal_MASE, h=6)
fea_set <- cal_features(tslist, database="M3", h=6)
outcome <- prepare_trainingset(acc_set, fea_set)
#' @param tslist a list of univariate time series
#' @param seasonal if FALSE, restricts to features suitable for non-seasonal data
#' @param m frequency of the time series
#' @param lagmax maximum lag at which to calculate the acf (quarterly series-5L and monthly-13L)
#' @param database whether the time series is from mcomp or other
#' @param h forecast horizon
#' @return dataframe: each column represent a feature and each row represent a time series
#' @importFrom magrittr %>%
#' @author Thiyanga Talagala
#' @export
cal_features <- function(tslist, seasonal=FALSE, m=1, lagmax=2L, database, h){ # tslist = yearly_m1,
if (database == "other") {
train_test <- lapply(tslist, function(temp){list(training=head_ts(temp,h), test=tail_ts(temp, h))})
} else {
train_test <- lapply(tslist, function(temp){list(training=temp$x, test=temp$xx)})
}
train <- lapply(train_test, function(temp){temp$training})
ts_features_pkg <- tsfeatures::tsfeatures(train, c("entropy",
"lumpiness",
"stability",
"hurst",
"stl_features",
"acf_features",
"pacf_features",
"nonlinearity"))
if (seasonal==FALSE){
ts_features1 <- ts_features_pkg %>% dplyr::select ("entropy", "lumpiness", "stability", "hurst",
"trend", "spike", "linearity", "curvature",
"e_acf1", "x_acf1", "diff1_acf1", "diff2_acf1",
"x_pacf5","diff1x_pacf5", "diff2x_pacf5", "nonlinearity")
seer_features_nonseasonal <- lapply(train, function(temp1){c(
seer::e_acf1(temp1),
seer::unitroot(temp1))})
seer_features_nonseasonal_DF <- as.data.frame(do.call("rbind", seer_features_nonseasonal))
ts_features <- dplyr::bind_cols(ts_features1, seer_features_nonseasonal_DF)
} else {
ts_features1 <- ts_features_pkg %>% dplyr::select ("entropy", "lumpiness", "stability", "hurst",
"trend", "spike", "linearity", "curvature",
"e_acf1", "x_acf1", "diff1_acf1", "diff2_acf1",
"x_pacf5","diff1x_pacf5", "diff2x_pacf5","nonlinearity", "seasonal_strength",
"seas_pacf")
seer_features_seasonal <- lapply(train, function(temp1){c(seer::holtWinter_parameters(temp1),
acf_seasonalDiff(temp1, m, lagmax))})
seer_features_seasonal_DF <- as.data.frame(do.call("rbind", seer_features_seasonal))
ts_features <- dplyr::bind_cols(ts_features1, seer_features_seasonal_DF)
}
ts_featuresDF <- as.data.frame(ts_features)
ts_featuresDF <- dplyr::rename(ts_featuresDF, "spikiness" = "spike")
ts_featuresDF <- dplyr::rename(ts_featuresDF, "y_acf1" = "x_acf1")
ts_featuresDF <- dplyr::rename(ts_featuresDF, "diff1y_acf1" = "diff1_acf1")
ts_featuresDF <- dplyr::rename(ts_featuresDF, "diff2y_acf1" = "diff2_acf1")
ts_featuresDF <- dplyr::rename(ts_featuresDF, "y_pacf5" = "x_pacf5")
ts_featuresDF <- dplyr::rename(ts_featuresDF, "diff1y_pacf5" = "diff1x_pacf5")
ts_featuresDF <- dplyr::rename(ts_featuresDF, "diff2y_pacf5" = "diff2x_pacf5")
if(seasonal==TRUE){
ts_featuresDF <- dplyr::rename(ts_featuresDF, "seasonality" = "seasonal_strength")
}
length <- lapply(train, function(temp){length(temp)})
length <- unlist(length)
ts_featuresDF$N <- length
seer_features <- lapply(train, function(temp1){c(seer::acf5(temp1), seer::holt_parameters(temp1))})
seer_feature_DF <- as.data.frame(do.call("rbind", seer_features))
featureDF <- dplyr::bind_cols(ts_featuresDF,seer_feature_DF)
return(featureDF)
}
#'@examples
require(Mcomp)
data(M3)
yearly_m3 <- subset(M3, "yearly")
cal_features(yearly_m3, database="M3", h=6)
library(ForeCA)
fea_set <- cal_features(tslist, database="M3", h=6)
library(ForeCA)
fea_set <- cal_features(tslist, database="M3", h=6)
library(tsfeatures)
fea_set <- cal_features(tslist, database="M3", h=6)
outcome <- prepare_trainingset(acc_set, fea_set)
library(tidyverse)
outcome <- prepare_trainingset(acc_set, fea_set)
outcome$trainingset
outcome$modelinfo
library(seer)
library(seer)
training <- rnorm(100)
mstl(training)
stlf(training)
ww <- subset(M4, "weekly")
data("M4")
ww <- subset(M4, "weekly")
library(seer)
data("M4")
ww <- subset(M4, "weekly")
#' @param M if TRUE, y is considered to be a Mcomp data object
#' @param Future if future=TRUE, the simulated observations are conditional on the historical observations.
#' In other words, they are possible future sample paths of the time series. But if future=FALSE, the historical
#' data are ignored, and the simulations are possible realizations of the time series model that
#' are not connected to the original data.
#' @param Length length of the simulated time series. If future = FALSE, the Length agument should be NA.
#' @param extralength extra length need to be added for simulated time series
#' @return A list of time series.
#' @author Thiyanga Talagala
#' @export
sim_mstlbased <- function(y, Nsim, Combine=TRUE, M=TRUE, Future=FALSE, Length=NA, extralength=NA){
if (M ==TRUE){
if ("Combine"==TRUE){
train <- y$x
test <-  y$xx
combined <- ts.union(train, test)
combined <- pmin(combined[,1], combined[,2], na.rm = TRUE)
}else{
combined <- y$x}
}else{
combined <- y
}
if(frequency(combined)==1 | length(combined) <= 2*frequency(combined))
return(NA)
fit <- forecast::mstl(combined)
if (!is.na(Length)){length_series <- Length
} else if (!is.na(extralength)) {
length_series <- length(combined)+extralength
} else {
length_series <- length(combined)
}
mat <- list()
for(i in 1:Nsim){
mat[[i]] <- simulate(fit$model, nsim=length_series, future=Future)}
return (mat)
}
#'@examples
library(seer)
data(M4)
weekly_m4 <- subset(M4, "weekly")
sim_mstlbased(weekly_m4[[1]], 2, Combine=FALSE, M=TRUE, Future=FALSE)
y
combined <- y
if (M ==TRUE){
if ("Combine"==TRUE){
train <- y$x
test <-  y$xx
combined <- ts.union(train, test)
combined <- pmin(combined[,1], combined[,2], na.rm = TRUE)
}else{
combined <- y$x}
}else{
combined <- y
}
fit <- forecast::mstl(combined)
combined
combined <- combined$x
fit <- forecast::mstl(combined)
fit$model
fit
fit <- forecast::mstl(combined)
forecast(fit, h=1)
fit
fit <- forecast::stlf(combined)
forecast(fit, h=1)
tryCatch({
fit <- forecast::hw(y)
output <- c(hwalpha = unname(fit$model$par["alpha"]),
hwbeta = unname(fit$model$par["beta"]),
hwgamma = unname(fit$model$par["gamma"]))
return(output)
}, error=function(e){return(rep(NA, 3))})
#' Parameter estimates of Holt-Winters seasonal method
#'
#' Estimate the smoothing parameter for the level-alpha and
#' the smoothing parameter for the trend-beta, and seasonality-gamma
#' @param y a univariate time series
#' @return A vector of 3 values: alpha, beta, gamma
#' @author Thiyanga Talagala
#' @export
holtWinter_parameters <- function(y){
tryCatch({
fit <- forecast::hw(y)
output <- c(hwalpha = unname(fit$model$par["alpha"]),
hwbeta = unname(fit$model$par["beta"]),
hwgamma = unname(fit$model$par["gamma"]))
return(output)
}, error=function(e){return(rep(NA, 3))})
}
y <- rep(10,10)
holtWinter_parameters(y)
hw(y)
library(forecast)
hw(y)
y <- as.ts(y)
hw(y)
y <- ts(y, frequency=1)
hw(y)
y
frequency(y)
fit <- forecast::hw(y)
#' Parameter estimates of Holt-Winters seasonal method
#'
#' Estimate the smoothing parameter for the level-alpha and
#' the smoothing parameter for the trend-beta, and seasonality-gamma
#' @param y a univariate time series
#' @return A vector of 3 values: alpha, beta, gamma
#' @author Thiyanga Talagala
#' @export
holtWinter_parameters <- function(y){
tryCatch({
fit <- forecast::hw(y)
output <- c(hwalpha = unname(fit$model$par["alpha"]),
hwbeta = unname(fit$model$par["beta"]),
hwgamma = unname(fit$model$par["gamma"]))
return(output)
}, error=function(e){return(rep(NA, 3))})
}
holtWinter_parameters
holtWinter_parameters(y)
library(seer)
c(alpha=5)
library(Mcomp)
y1 <- subset(M3, "yearly")
a <- y1[[1]]$x
a
#' Parameter estimates of Holt's linear trend method
#'
#' Estimate the smoothing parameter for the level-alpha and
#' the smoothing parameter for the trend-beta.
#' @param x a univariate time series
#' @return a vector of 2 values: alpha, beta.
#' @author Thiyanga Talagala
#' @export
holt_parameters <- function(x){
# parameter estimates of holt linear trend model
# tryCatch({
fit <- forecast::holt(x)
output <- c(alpha = unname(fit$model$par["alpha"]),
beta = unname(fit$model$par["beta"]))
return(output)
#  }, error=function(e){return(rep(NA, 2))})
}
holt_parameters(a)
c(alpha=NA, beta=NA)
library(seer)
